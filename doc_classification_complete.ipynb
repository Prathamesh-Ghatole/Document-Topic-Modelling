{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "Here, we'll use Gensim's LDA (Latent Dirichlet Allocation) model to model topics in `newsgroup_data`. \n",
    "First, we need to finish the code in the cell below by using gensim.models.ldamodel.LdaModel constructor to estimate LDA model parameters on the corpus, and save to the variable `ldamodel`. \n",
    "\n",
    "Finally, we'll Extract 10 topics using `corpus` and `id_map`, and with `passes=25` and `random_state=34`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample row from our input data is as follows:\n",
      "===================\n",
      "\n",
      " \n",
      "There would be no problems as long as the OS didn't set up a DMA transfer\n",
      "to an area above the 16 mb area (the DMA controller probably can't be\n",
      "programmed that way anyways, so there probably isin't a problem with this)\n",
      "\n",
      "\n",
      "===================\n",
      "We've passed our data through a CountVectorizer, and then fitted and transformed it as our training data.\n",
      "\n",
      "\n",
      "In the training data:\n",
      "Number of corpora = 2000. Total number of characters = 1667950\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the list of documents\n",
    "with open('data/newsgroups', 'rb') as f:\n",
    "    newsgroup_data = pickle.load(f)\n",
    "\n",
    "print(\"A sample row from our input data is as follows:\\n===================\\n\\n\", newsgroup_data[5])\n",
    "\n",
    "char_count = 0\n",
    "for item in newsgroup_data:\n",
    "    char_count += len(item)\n",
    "\n",
    "# Use CountVectorizor to find three letter tokens, remove stop_words, \n",
    "# remove tokens that don't appear in at least 20 documents,\n",
    "# remove tokens that appear in more than 20% of the documents\n",
    "vect = CountVectorizer(min_df=20, max_df=0.2, stop_words='english', \n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "\n",
    "# Fit and transform\n",
    "X = vect.fit_transform(newsgroup_data)\n",
    "print(\"\\n\\n===================\\nWe've passed our data through a CountVectorizer, and then fitted and transformed it as our training data.\")\n",
    "print(\"\\n\\nIn the training data:\\nNumber of corpora = {}. Total number of characters = {}\".format(len(newsgroup_data), char_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we'll convert our training data X to gensim corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to gensim corpus.\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "print(\"Now, we'll convert our training data X to gensim corpus\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a mapping from word IDs to words for loading into the LdaModel.\n",
      "The ID map is as follows:\n",
      "\n",
      "(76, 'best')\n",
      "(335, 'group')\n",
      "(33, 'america')\n",
      "(409, 'know')\n",
      "(726, 'similar')\n",
      "(544, 'organization')\n",
      "(23, 'address')\n",
      "(514, 'new')\n",
      "(899, 'york')\n",
      "(842, 'usa')\n"
     ]
    }
   ],
   "source": [
    "# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())\n",
    "\n",
    "\n",
    "####\n",
    "print(\"Creating a mapping from word IDs to words for loading into the LdaModel.\")\n",
    "print(\"The ID map is as follows:\\n\")\n",
    "for items in list(id_map.items())[:10]:\n",
    "    print(items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Successful!\n",
      "Params:\n",
      "Number of topics: 10,\n",
      "passes: 25,\n",
      "random state: 34\n",
      "CPU times: total: 1min 32s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Use the gensim.models.ldamodel.LdaModel constructor to estimate \n",
    "# LDA model parameters on the corpus, and save to the variable `ldamodel`\n",
    "\n",
    "# Your code here:\n",
    "trained_ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word=id_map, passes=25, random_state=34)\n",
    "print('''Training Successful!\n",
    "Params:\n",
    "Number of topics: 10,\n",
    "passes: 25,\n",
    "random state: 34''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda_topics\n",
    "\n",
    "Our lda model returns a list of topic numbers, and their probability\n",
    "However, these are TOPIC NUMBERS, and they aren't named/\n",
    "\n",
    "Using `trained_ldamodel`, we can find a list of the 10 topics and the most significant 10 words in each topic. \n",
    "We can then use this info to manully name our name our TOPIC NUMBERS.\n",
    "\n",
    "First, we'll see the topic number & it's respective keywords.\n",
    "This will be structured as a list of 10 tuples where each tuple takes on the form:\n",
    "\n",
    "`(9, '0.068*\"space\" + 0.036*\"nasa\" + 0.021*\"science\" + 0.020*\"edu\" + 0.019*\"data\" + 0.017*\"shuttle\" + 0.015*\"launch\" + 0.015*\"available\" + 0.014*\"center\" + 0.014*\"sci\"')`\n",
    "\n",
    "Now, we can easily see that the topic list can be \"Space, nasa, science etc.\"\n",
    "Since \"space\" seems to be the most relevant topic, we'll rename TOPIC NUMBER 9 as \"space\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.056*\"edu\" + 0.043*\"com\" + 0.033*\"thanks\" + 0.022*\"mail\" + 0.021*\"know\" + 0.020*\"does\" + 0.014*\"info\" + 0.012*\"monitor\" + 0.010*\"looking\" + 0.010*\"don\"'),\n",
       " (1,\n",
       "  '0.024*\"ground\" + 0.018*\"current\" + 0.018*\"just\" + 0.013*\"want\" + 0.013*\"use\" + 0.011*\"using\" + 0.011*\"used\" + 0.010*\"power\" + 0.010*\"speed\" + 0.010*\"output\"'),\n",
       " (2,\n",
       "  '0.061*\"drive\" + 0.042*\"disk\" + 0.033*\"scsi\" + 0.030*\"drives\" + 0.028*\"hard\" + 0.028*\"controller\" + 0.027*\"card\" + 0.020*\"rom\" + 0.018*\"floppy\" + 0.017*\"bus\"'),\n",
       " (3,\n",
       "  '0.023*\"time\" + 0.015*\"atheism\" + 0.014*\"list\" + 0.013*\"left\" + 0.012*\"alt\" + 0.012*\"faq\" + 0.012*\"probably\" + 0.011*\"know\" + 0.011*\"send\" + 0.010*\"months\"'),\n",
       " (4,\n",
       "  '0.025*\"car\" + 0.016*\"just\" + 0.014*\"don\" + 0.014*\"bike\" + 0.012*\"good\" + 0.011*\"new\" + 0.011*\"think\" + 0.010*\"year\" + 0.010*\"cars\" + 0.010*\"time\"'),\n",
       " (5,\n",
       "  '0.030*\"game\" + 0.027*\"team\" + 0.023*\"year\" + 0.017*\"games\" + 0.016*\"play\" + 0.012*\"season\" + 0.012*\"players\" + 0.012*\"win\" + 0.011*\"hockey\" + 0.011*\"good\"'),\n",
       " (6,\n",
       "  '0.017*\"information\" + 0.014*\"help\" + 0.014*\"medical\" + 0.012*\"new\" + 0.012*\"use\" + 0.012*\"000\" + 0.012*\"research\" + 0.011*\"university\" + 0.010*\"number\" + 0.010*\"program\"'),\n",
       " (7,\n",
       "  '0.022*\"don\" + 0.021*\"people\" + 0.018*\"think\" + 0.017*\"just\" + 0.012*\"say\" + 0.011*\"know\" + 0.011*\"does\" + 0.011*\"good\" + 0.010*\"god\" + 0.009*\"way\"'),\n",
       " (8,\n",
       "  '0.034*\"use\" + 0.023*\"apple\" + 0.020*\"power\" + 0.016*\"time\" + 0.015*\"data\" + 0.015*\"software\" + 0.012*\"pin\" + 0.012*\"memory\" + 0.012*\"simms\" + 0.011*\"port\"'),\n",
       " (9,\n",
       "  '0.068*\"space\" + 0.036*\"nasa\" + 0.021*\"science\" + 0.020*\"edu\" + 0.019*\"data\" + 0.017*\"shuttle\" + 0.015*\"launch\" + 0.015*\"available\" + 0.014*\"center\" + 0.014*\"sci\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lda_topics():\n",
    "    return list(trained_ldamodel.show_topics(num_topics=10, num_words=10))\n",
    "\n",
    "lda_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic_names\n",
    "\n",
    "From the list of the following given topics, assign topic names to the topics you found. If none of these names best matches the topics you found, create a new 1-3 word \"title\" for the topic.\n",
    "\n",
    "Topics: Health, Science, Automobiles, Politics, Government, Travel, Computers & IT, Sports, Business, Society & Lifestyle, Religion, Education.\n",
    "\n",
    "*This function should return a list of 10 strings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Education',\n",
       " 1: 'Science',\n",
       " 2: 'Computers & IT',\n",
       " 3: 'Religion',\n",
       " 4: 'Automobiles',\n",
       " 5: 'Sports',\n",
       " 6: 'Science',\n",
       " 7: 'Religion',\n",
       " 8: 'Computers & IT',\n",
       " 9: 'Science'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually assigning topic names to each topic number.\n",
    "\n",
    "topic_names = ['Education','Science','Computers & IT','Religion','Automobiles','Sports','Science','Religion','Computers & IT','Science']\n",
    "topic_numbers = [int(i) for i in range(10)]\n",
    "\n",
    "name_mapping = {}\n",
    "name_mapping.update(list(zip(topic_numbers, topic_names)))\n",
    "name_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic_distribution\n",
    "\n",
    "For the new document `new_doc`, let's find the topic distribution. \n",
    "\n",
    "As with all input text, We'll use vect.transform on the the new doc, and Sparse2Corpus to convert the sparse matrix to gensim corpus.\n",
    "\n",
    "*This function will return a list of tuples, where each tuple is `(#topic, probability)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function takes in a list of strings, preprocesses it.\n",
    "# it then returns a list of tuples containing topic names and their respective probabilities.\n",
    "\n",
    "def topic_distribution(doc_to_test):\n",
    "    \n",
    "    sparse_doc = vect.transform(doc_to_test)\n",
    "    gen_corpus = gensim.matutils.Sparse2Corpus(sparse_doc, documents_columns=False)\n",
    "    \n",
    "    topics = sorted(list(trained_ldamodel[gen_corpus])[0], key=lambda x: -x[1]) # It's a list of lists! We just want the first one.\n",
    "    return [(name_mapping[x[0]], x[1]) for x in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Religion', 0.4964944),\n",
       " ('Science', 0.34348097),\n",
       " ('Sports', 0.020004135),\n",
       " ('Automobiles', 0.020004045),\n",
       " ('Science', 0.02000333),\n",
       " ('Computers & IT', 0.020003129),\n",
       " ('Education', 0.020003106),\n",
       " ('Science', 0.020002974),\n",
       " ('Religion', 0.020002646),\n",
       " ('Computers & IT', 0.020001281)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = [\"\\n\\nIt's my understanding that the freezing will start to occur because \\\n",
    "of the\\ngrowing distance of Pluto and Charon from the Sun, due to it's\\nelliptical orbit. \\\n",
    "It is not due to shadowing effects. \\n\\n\\nPluto can shadow Charon, and vice-versa.\\n\\nGeorge \\\n",
    "Krumins\\n-- \"]\n",
    "\n",
    "topic_distribution(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Religion', 0.9181615)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = ['It is considered to be the oldest living religion in the world. Hinduism is often called a \"way of life\", and anyone sincerely following that way of life can consider themselves to be a Hindu.']\n",
    "\n",
    "topic_distribution(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Science', 0.49019933),\n",
       " ('Computers & IT', 0.37642974),\n",
       " ('Computers & IT', 0.016674902),\n",
       " ('Science', 0.01667401),\n",
       " ('Religion', 0.016671907),\n",
       " ('Education', 0.01667108),\n",
       " ('Religion', 0.01667102),\n",
       " ('Science', 0.016670303),\n",
       " ('Sports', 0.016668897),\n",
       " ('Automobiles', 0.016668787)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = ['''Linux is a family of open-source Unix-like operating systems based on the Linux kernel,\n",
    "an operating system kernel first released on September 17, 1991, by Linus Torvalds.\n",
    "Linux is typically packaged in a Linux distribution.''']\n",
    "topic_distribution(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sports', 0.8874408),\n",
       " ('Religion', 0.012510252),\n",
       " ('Science', 0.0125086205),\n",
       " ('Religion', 0.012507285),\n",
       " ('Computers & IT', 0.012507194),\n",
       " ('Computers & IT', 0.012506805),\n",
       " ('Science', 0.012505957),\n",
       " ('Science', 0.012505735),\n",
       " ('Automobiles', 0.012504364),\n",
       " ('Education', 0.012502977)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4 = ['''With 15 matches left to play in the league stage of IPL 2022, as of Monday May 9,\n",
    "there remain as many as 32,768 possible combinations of results. \n",
    "Sunday's two games have brought that figure down from a staggering 1,31,072. ''']\n",
    "\n",
    "topic_distribution(test4)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "2qbcK",
   "launcher_item_id": "pi9Sh",
   "part_id": "kQiwX"
  },
  "interpreter": {
   "hash": "39088717afcb7a198025c6db1dfe9ad2178ef5e15752e36a70bc4c3749f172dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env_mla': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
