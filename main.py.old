import numpy as np
import pandas as pd
import pickle
import colorama
import gensim
import nltk
from nltk.corpus import wordnet as wn
from sklearn.feature_extraction.text import CountVectorizer

# Download essential components for nltk
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('omw-1.4')

# Importing custom library functions
from lib.functions import *


# First, let's load up our training data.
# paraphrases is a DataFrame which contains the following columns: `Quality`, `D1`, and `D2`.
paraphrases = pd.read_csv('paraphrases.csv')

# `Quality` is an indicator variable which indicates if the two documents `D1` and `D2` are 
# paraphrases of one another (1 for paraphrase, 0 for not paraphrase).

